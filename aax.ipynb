Here are the new cells you can copy and paste into your Google Colab notebook, one by one, after the setup cells you showed in your screenshots.New Cell 1: Additional Imports & ConstantsYou've already imported os, pandas, torch, etc. Here are the rest of the imports you'll need, plus the constants for the model.import torch # <-- I've added this line to fix the error
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.models as models
from torchvision.transforms import functional as F

import albumentations as A
from albumentations.pytorch import ToTensorV2

import numpy as np
import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import multilabel_confusion_matrix, f1_score

# --- Constants ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {DEVICE}")

IMG_SIZE = 224
BATCH_SIZE = 32
LEARNING_RATE = 1e-4
EPOCHS = 10 # Start with 10, increase if needed

# Disease categories from your 'data.xlsx'
CLASSES = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']

New Cell 2: Data Preprocessing FunctionThis cell defines the function that handles your request to "consider the left and right eye as two separate eyes".def preprocess_dataframe(labels_path, images_dir):
    """
    Loads the Excel file and transforms it to treat each eye as a separate sample.
    """
    try:
        df = pd.read_excel(labels_path)
    except FileNotFoundError:
        print(f"Error: Could not find labels file at {labels_path}")
        return pd.DataFrame() # Return empty df
    except Exception as e:
        print(f"Error loading Excel file: {e}")
        return pd.DataFrame()

    # Create two separate dataframes: one for left, one for right
    df_left = df[['Left-Fundus'] + CLASSES].copy()
    df_right = df[['Right-Fundus'] + CLASSES].copy()

    # Rename columns to be consistent
    df_left.rename(columns={'Left-Fundus': 'filename'}, inplace=True)
    df_right.rename(columns={'Right-Fundus': 'filename'}, inplace=True)

    # Add image path
    # This uses the 'images_dir' variable from your setup
    df_left['image_path'] = df_left['filename'].apply(lambda x: os.path.join(images_dir, x))
    df_right['image_path'] = df_right['filename'].apply(lambda x: os.path.join(images_dir, x))

    # Combine them into one single dataframe
    df_combined = pd.concat([df_left, df_right], ignore_index=True)

    # Drop rows where the image file might be missing or entry is bad
    df_combined = df_combined.dropna(subset=['filename'])
    
    print(f"Original patient count: {len(df)}")
    print(f"Transformed eye count: {len(df_combined)}")
    
    return df_combined

New Cell 3: PyTorch Dataset & AugmentationsThis cell defines the EyeDataset class to load images and the get_transforms function for data augmentation.class EyeDataset(Dataset):
    def __init__(self, df, transforms=None):
        self.df = df
        self.image_paths = df['image_path'].values
        self.labels = df[CLASSES].values.astype(np.float32) # Ensure labels are float
        self.transforms = transforms

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        
        try:
            # Read image using OpenCV
            image = cv2.imread(image_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        except Exception as e:
            print(f"Error loading image {image_path}: {e}")
            # Return a dummy image and label if error
            image = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
            label = np.zeros(len(CLASSES), dtype=np.float32)
            if self.transforms:
                image = self.transforms(image=image)['image']
            return image, label

        label = self.labels[idx]

        if self.transforms:
            augmented = self.transforms(image=image)
            image = augmented['image']
            
        return image, label

def get_transforms(is_train=True):
    if is_train:
        return A.Compose([
            A.Resize(IMG_SIZE, IMG_SIZE),
            A.HorizontalFlip(p=0.5),
            A.RandomBrightnessContrast(p=0.2),
            A.Rotate(limit=15, p=0.3),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
    else:
        return A.Compose([
            A.Resize(IMG_SIZE, IMG_SIZE),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])

New Cell 4: Model DefinitionThis defines the function to load a pre-trained ResNet-50 and adapt it for your 8-class problem.def get_model(num_classes=8):
    """
    Loads a pre-trained ResNet-50 and replaces the final layer.
    """
    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
    
    # Replace the final fully connected layer
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, num_classes)
    
    return model

New Cell 5: Training & Validation FunctionsThese are the helper functions that run the training and validation for one epoch.def train_one_epoch(model, loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    
    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)
        
        # Zero gradients
        optimizer.zero_grad()
        
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # Backward pass and optimize
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item() * images.size(0)
        
    epoch_loss = running_loss / len(loader.dataset)
    return epoch_loss

def validate_one_epoch(model, loader, criterion, device):
    model.eval()
    running_loss = 0.0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item() * images.size(0)
            
            # Get predictions (apply sigmoid and threshold)
            preds = torch.sigmoid(outputs) > 0.5
            
            all_preds.append(preds.cpu().numpy())
            all_labels.append(labels.cpu().numpy())
            
    epoch_loss = running_loss / len(loader.dataset)
    
    # Calculate metrics
    all_preds = np.concatenate(all_preds)
    all_labels = np.concatenate(all_labels)
    
    # Calculate F1 score (micro-average)
    f1 = f1_score(all_labels, all_preds, average='micro')
    
    return epoch_loss, f1

New Cell 6: Grad-CAM Implementation (Heatmaps)This is the code for your heatmap request. It includes the GradCAM class and a function to plot the results.class GradCAM:
    """
    Implementation of Grad-CAM to visualize model activations.
    """
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        
        # Register hooks
        self.target_layer.register_forward_hook(self._save_activations)
        self.target_layer.register_backward_hook(self._save_gradients)

    def _save_activations(self, module, input, output):
        self.activations = output

    def _save_gradients(self, module, grad_in, grad_out):
        self.gradients = grad_out[0]

    def __call__(self, x, class_idx=None):
        # Forward pass
        self.model.eval()
        output = self.model(x)
        
        if class_idx is None:
            # Use the class with the highest score
            class_idx = torch.argmax(output, dim=1).item()
            
        # Zero gradients
        self.model.zero_grad()
        
        # Backward pass for the target class
        target = torch.zeros_like(output)
        target[0, class_idx] = 1
        output.backward(gradient=target, retain_graph=True)
        
        # Get gradients and activations
        gradients = self.gradients
        activations = self.activations
        
        # Pool gradients
        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])
        
        # Weight activations
        for i in range(activations.shape[1]):
            activations[:, i, :, :] *= pooled_gradients[i]
            
        # Average weighted activations
        heatmap = torch.mean(activations, dim=1).squeeze()
        
        # ReLU
        heatmap = nn.functional.relu(heatmap)
        
        # Normalize
        heatmap /= torch.max(heatmap)
        
        return heatmap.cpu().detach().numpy()

def show_grad_cam(model, target_layer, img_tensor, original_img, class_idx=None, class_name=""):
    """
    Generates and plots the Grad-CAM heatmap.
    """
    # Get heatmap
    gc = GradCAM(model, target_layer)
    heatmap = gc(img_tensor.unsqueeze(0).to(DEVICE), class_idx)
    
    # Resize heatmap to original image size
    heatmap = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))
    
    # Normalize heatmap
    heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap))
    
    # Apply colormap
    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)
    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)
    
    # Superimpose heatmap on original image
    superimposed_img = np.uint8(heatmap_colored * 0.4 + original_img * 0.6)
    
    # Plot
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    
    axs[0].imshow(original_img)
    axs[0].set_title("Original.png")
    axs[0].axis('off')
    
    axs[1].imshow(heatmap_colored)
    axs[1].set_title(f"Grad-CAM Heatmap ({class_name})")
    axs[1].axis('off')
    
    axs[2].imshow(superimposed_img)
    axs[2].set_title("Overlay")
    axs[2].axis('off')
    
    plt.tight_layout()
    plt.show()

New Cell 7: Load Data and SplitThis cell runs the preprocessing function and splits your data into training and validation sets.# This uses the 'labels_file' and 'train_images_folder' from your setup
df = preprocess_dataframe(labels_file, train_images_folder)

if df.empty:
    print("Dataframe is empty. Check your paths and file.")
else:
    # Split data
    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)
    print(f"Data split: {len(train_df)} train, {len(val_df)} validation samples")

New Cell 8: Initialize Model & DataLoadersThis cell creates the Dataset and DataLoader objects and initializes the model, loss function, and optimizer.train_dataset = EyeDataset(train_df, transforms=get_transforms(is_train=True))
val_dataset = EyeDataset(val_df, transforms=get_transforms(is_train=False))

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

model = get_model(num_classes=len(CLASSES)).to(DEVICE)

# Multi-label classification requires BCEWithLogitsLoss
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

New Cell 9: Run TrainingThis is the main training loop. It will print the loss and F1 score for each epoch and save the best model.best_f1 = 0.0
print("\n--- Starting Training ---")
for epoch in range(EPOCHS):
    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)
    val_loss, val_f1 = validate_one_epoch(model, val_loader, criterion, DEVICE)
    
    print(f"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}")
    
    if val_f1 > best_f1:
        best_f1 = val_f1
        torch.save(model.state_dict(), 'best_model.pth')
        print(f"New best model saved with F1: {best_f1:.4f}")
        
print("--- Training Finished ---")

New Cell 10: Generate Grad-CAM HeatmapsAfter training, run this final cell to load the best model and visualize the heatmaps for a sample image.print("\nLoading best model for Grad-CAM analysis...")
model.load_state_dict(torch.load('best_model.pth'))
model.to(DEVICE).eval()

# 7. Generate Grad-CAM for a sample image
# Get a sample from the validation set
sample_idx = 10 # You can change this index to see other images

# Get data from dataset (which applies val transforms)
img_tensor, label = val_dataset[sample_idx]

# Get original image (for plotting)
original_img_path = val_dataset.image_paths[sample_idx]
original_img = cv2.imread(original_img_path)
original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)

# Get model prediction
with torch.no_grad():
    output = model(img_tensor.unsqueeze(0).to(DEVICE))
    probs = torch.sigmoid(output).cpu().numpy()[0]
    
print("\n--- Grad-CAM Analysis ---")
print(f"Image: {original_img_path}")
print("True Labels:")
for i, class_name in enumerate(CLASSES):
    if label[i] == 1:
        print(f"  - {class_name}")
        
print("\nModel Predictions (Probabilities):")
pred_indices = np.where(probs > 0.5)[0]
if len(pred_indices) == 0:
    print("  - Model predicts no abnormalities (or 'Normal' if N prob > 0.5)")
    pred_idx = np.argmax(probs) # Get highest prob class even if < 0.5
else:
    pred_idx = pred_indices[0] # Just pick the first predicted class for Grad-CAM

for i, class_name in enumerate(CLASSES):
    print(f"  - {class_name}: {probs[i]:.4f}")
    
# --- Generate Grad-CAM ---
# We target the final convolutional block of ResNet-50
target_layer = model.layer4[-1] 

# Get the class name for the prediction we're visualizing
pred_class_name = CLASSES[pred_idx]

print(f"\nGenerating Grad-CAM for predicted class: '{pred_class_name}' (index {pred_idx})")

show_grad_cam(
    model=model,
    target_layer=target_layer,
    img_tensor=img_tensor,
    original_img=original_img,
    class_idx=pred_idx,
    class_name=pred_class_name
)

